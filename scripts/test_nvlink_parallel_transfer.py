import torch
import time
import sys

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ»¡è¶³è¦æ±‚"""
    if not torch.cuda.is_available():
        print("âŒ CUDA ä¸å¯ç”¨")
        sys.exit(1)
    
    if torch.cuda.device_count() < 2:
        print("âŒ éœ€è¦è‡³å°‘ 2 ä¸ª GPU")
        sys.exit(1)
    
    # æ£€æŸ¥ NVLink è¿æ¥ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯ç”¨ nvidia-smi topo -m éªŒè¯ï¼‰
    print(f"âœ… æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ª GPU")
    for i in range(torch.cuda.device_count()):
        print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    print()

def parallel_bidirectional_transfer(size_mb=1024):
    """
    é€šè¿‡ç‹¬ç«‹ CUDA æµå®ç° GPU 0 â†” GPU 1 çš„å¹¶è¡ŒåŒå‘ä¼ è¾“
    """
    # åˆ›å»ºæ•°æ®ï¼ˆçº¦ size_mb MBï¼‰
    size = size_mb * 1024 * 1024 // 4  # float32 æ¯ä¸ªå…ƒç´  4 å­—èŠ‚
    data0 = torch.randn(size, device='cuda:0', dtype=torch.float32)
    data1 = torch.randn(size, device='cuda:3', dtype=torch.float32)
    
    # åˆ›å»ºç›®æ ‡å¼ é‡
    recv0 = torch.empty_like(data0)  # GPU 0 æ¥æ”¶æ¥è‡ª GPU 1 çš„æ•°æ®
    recv1 = torch.empty_like(data1)  # GPU 1 æ¥æ”¶æ¥è‡ª GPU 0 çš„æ•°æ®
    
    # åˆ›å»ºç‹¬ç«‹ CUDA æµ
    stream0 = torch.cuda.Stream(device='cuda:0')  # ç”¨äº GPU0â†’GPU1 ä¼ è¾“
    stream1 = torch.cuda.Stream(device='cuda:3')  # ç”¨äº GPU1â†’GPU0 ä¼ è¾“
    
    # åˆ›å»º CUDA äº‹ä»¶ç”¨äºç²¾ç¡®è®¡æ—¶
    start_event = torch.cuda.Event(enable_timing=True)
    end_event = torch.cuda.Event(enable_timing=True)
    
    print(f"ğŸ“Š ä¼ è¾“æ•°æ®é‡: {size_mb} MB (æ¯ä¸ªæ–¹å‘)")
    print("=" * 60)
    
    # ========== ä¸²è¡Œä¼ è¾“ï¼ˆåŸºçº¿ï¼‰==========
    print("\n[1] ä¸²è¡Œä¼ è¾“ï¼ˆåŸºçº¿ï¼‰:")
    torch.cuda.synchronize()
    t0 = time.time()
    
    # GPU0 â†’ GPU1
    recv1.copy_(data0)  # é˜»å¡æ“ä½œ
    # GPU1 â†’ GPU0
    recv0.copy_(data1)  # é˜»å¡æ“ä½œ
    
    torch.cuda.synchronize()
    serial_time = time.time() - t0
    print(f"   è€—æ—¶: {serial_time*1000:.2f} ms")
    print(f"   ç­‰æ•ˆå¸¦å®½: {2 * size_mb / serial_time:.2f} MB/s")
    
    # éªŒè¯æ•°æ®æ­£ç¡®æ€§
    assert torch.allclose(recv0.cpu(), data1.cpu(), atol=1e-6), "GPU0 æ¥æ”¶æ•°æ®é”™è¯¯"
    assert torch.allclose(recv1.cpu(), data0.cpu(), atol=1e-6), "GPU1 æ¥æ”¶æ•°æ®é”™è¯¯"
    
    # ========== å¹¶è¡Œä¼ è¾“ï¼ˆä½¿ç”¨ CUDA æµï¼‰==========
    print("\n[2] å¹¶è¡ŒåŒå‘ä¼ è¾“ï¼ˆCUDA æµ + non_blockingï¼‰:")
    
    # é‡ç½®æ¥æ”¶ç¼“å†²åŒº
    recv0.zero_()
    recv1.zero_()
    
    torch.cuda.synchronize()
    start_event.record()
    
    # åœ¨ç‹¬ç«‹æµä¸­å¯åŠ¨éé˜»å¡ä¼ è¾“
    with torch.cuda.stream(stream0):
        # GPU0 â†’ GPU1 (stream0 æ§åˆ¶)
        recv1.copy_(data0, non_blocking=True)
    
    with torch.cuda.stream(stream1):
        # GPU1 â†’ GPU0 (stream1 æ§åˆ¶)
        recv0.copy_(data1, non_blocking=True)
    
    # ç­‰å¾…ä¸¤ä¸ªæµå®Œæˆ
    stream0.synchronize()
    stream1.synchronize()
    
    end_event.record()
    end_event.synchronize()
    parallel_time = start_event.elapsed_time(end_event) / 1000  # ç§’
    
    print(f"   è€—æ—¶: {parallel_time*1000:.2f} ms")
    print(f"   ç­‰æ•ˆå¸¦å®½: {2 * size_mb / parallel_time:.2f} MB/s")
    
    # éªŒè¯æ•°æ®æ­£ç¡®æ€§
    assert torch.allclose(recv0.cpu(), data1.cpu(), atol=1e-6), "GPU0 æ¥æ”¶æ•°æ®é”™è¯¯"
    assert torch.allclose(recv1.cpu(), data0.cpu(), atol=1e-6), "GPU1 æ¥æ”¶æ•°æ®é”™è¯¯"
    
    # ========== æ€§èƒ½å¯¹æ¯” ==========
    print("\n" + "=" * 60)
    print(f"â±ï¸  æ€§èƒ½å¯¹æ¯”:")
    print(f"   ä¸²è¡Œè€—æ—¶: {serial_time*1000:.2f} ms")
    print(f"   å¹¶è¡Œè€—æ—¶: {parallel_time*1000:.2f} ms")
    speedup = serial_time / parallel_time
    print(f"   âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    if speedup > 1.5:
        print("   âœ… æˆåŠŸå®ç°å¹¶è¡ŒåŒå‘ä¼ è¾“ï¼ˆNVLink å…¨åŒå·¥ç‰¹æ€§ç”Ÿæ•ˆï¼‰")
    else:
        print("   âš ï¸  åŠ é€Ÿä¸æ˜æ˜¾ï¼ˆå¯èƒ½å— PCIe é™åˆ¶æˆ–æ•°æ®é‡å¤ªå°ï¼‰")
    
    print("=" * 60)

if __name__ == "__main__":
    check_environment()
    parallel_bidirectional_transfer(size_mb=34*6)  # ä¼ è¾“ 2GB/æ–¹å‘